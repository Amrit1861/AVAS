import cv2
import numpy as np
from ultralytics import YOLO
from sort.sort import Sort

# Load YOLOv8 model and SORT tracker
model = YOLO("C:/folder9.6/college/MajorProject4thYear/AVASProject/AVAS/weights/yolo12s.pt")  # Replace with your custom model path if needed
tracker = Sort()

# ---------------- Lane Detection Functions ---------------- #
def region_of_interest(img, vertices):
    mask = np.zeros_like(img)
    cv2.fillPoly(mask, vertices, 255)
    return cv2.bitwise_and(img, mask)

def draw_lane_lines(img, left_line, right_line):
    line_img = np.zeros_like(img)
    if left_line is not None:
        cv2.line(line_img, (left_line[0], left_line[1]), (left_line[2], left_line[3]), (0, 255, 0), 10)
    if right_line is not None:
        cv2.line(line_img, (right_line[0], right_line[1]), (right_line[2], right_line[3]), (0, 255, 0), 10)
    return cv2.addWeighted(img, 0.8, line_img, 1, 1)

def lane_pipeline(image):
    height, width = image.shape[:2]

    roi_vertices = [
        (int(width * 0.1), height),
        (int(width * 0.45), int(height * 0.55)),
        (int(width * 0.55), int(height * 0.55)),
        (int(width * 0.9), height)
    ]

    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(blur, 50, 150)
    cropped = region_of_interest(edges, np.array([roi_vertices], np.int32))

    lines = cv2.HoughLinesP(cropped, 1, np.pi / 180, 40, minLineLength=40, maxLineGap=100)

    left_x, left_y, right_x, right_y = [], [], [], []

    min_slope = 0.4
    max_slope = 2.0

    if lines is not None:
        for line in lines:
            x1, y1, x2, y2 = line[0]
            if x2 - x1 == 0:
                continue  # skip vertical
            slope = (y2 - y1) / (x2 - x1)

            if abs(slope) < min_slope or abs(slope) > max_slope:
                continue

            if slope < 0:
                left_x.extend([x1, x2])
                left_y.extend([y1, y2])
            else:
                right_x.extend([x1, x2])
                right_y.extend([y1, y2])

    min_y = int(height * 0.55)
    max_y = height
    left_line, right_line = None, None

    if left_x and left_y:
        left_fit = np.polyfit(left_y, left_x, 1)
        x_start = int(left_fit[0] * max_y + left_fit[1])
        x_end = int(left_fit[0] * min_y + left_fit[1])
        if 0 <= x_start <= width and 0 <= x_end <= width:
            left_line = [x_start, max_y, x_end, min_y]

    if right_x and right_y:
        right_fit = np.polyfit(right_y, right_x, 1)
        x_start = int(right_fit[0] * max_y + right_fit[1])
        x_end = int(right_fit[0] * min_y + right_fit[1])
        if 0 <= x_start <= width and 0 <= x_end <= width:
            right_line = [x_start, max_y, x_end, min_y]

    lane_image = draw_lane_lines(image.copy(), left_line, right_line)

    # Optional: show ROI overlay with only side lines
    debug_overlay = image.copy()
    roi_pts = np.array(roi_vertices, np.int32)

    # Draw left and right edges only
    cv2.line(debug_overlay, tuple(roi_pts[0]), tuple(roi_pts[1]), (0, 255, 255), 2)
    cv2.line(debug_overlay, tuple(roi_pts[2]), tuple(roi_pts[3]), (0, 255, 255), 2)

    lane_image = cv2.addWeighted(lane_image, 0.8, debug_overlay, 0.4, 0)

    return lane_image


# ---------------- Distance Estimation ---------------- #
def estimate_distance(bbox_height, known_height=1.5, focal_length=700):
    if bbox_height == 0:
        return float('inf')
    return round((known_height * focal_length) / bbox_height, 2)

# ---------------- Video Processing ---------------- #



cap = cv2.VideoCapture("C:/folder9.6/college/MajorProject4thYear/AVASProject/AVAS/video/T4.mp4")  # Replace with your video path

if not cap.isOpened():
    print("[ERROR] Unable to open video file.")
    exit()
else:
    print("[INFO] Video file loaded successfully.")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Lane detection
    frame_with_lanes = lane_pipeline(frame.copy())

    # YOLO detection
    results = model(frame, verbose=False)[0]
    detections = []

    for r in results.boxes:
        x1, y1, x2, y2 = map(int, r.xyxy[0])
        conf = float(r.conf)
        cls = int(r.cls)
        label = model.names[cls]

        if conf > 0.3:  # Adjust confidence threshold if needed
            detections.append([x1, y1, x2, y2, conf])

    # Fix: Handle empty detection safely
    if len(detections) == 0:
        detections = np.empty((0, 5))
    else:
        detections = np.array(detections)

    tracks = tracker.update(detections)

    # Draw tracked objects
    for track in tracks:
        x1, y1, x2, y2, track_id = map(int, track)
        height = y2 - y1
        distance = estimate_distance(height)

        cv2.rectangle(frame_with_lanes, (x1, y1), (x2, y2), (0, 255, 255), 2)
        cv2.putText(frame_with_lanes, f"ID:car", (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)
        cv2.putText(frame_with_lanes, f"Distance: {distance}m", (x1, y2 + 20),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

    # Show the frame
    cv2.imshow("Lane and Object Detection", frame_with_lanes)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

# ---------------- Real-Time Processing ---------------- #
'''
cap = cv2.VideoCapture(0)  # Use webcam

if not cap.isOpened():
    print("[ERROR] Unable to access the webcam.")
    exit()
else:
    print("[INFO] Webcam accessed successfully.")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    frame_with_lanes = lane_pipeline(frame.copy())
    results = model(frame, verbose=False)[0]

    detections = []
    for r in results.boxes:
        x1, y1, x2, y2 = map(int, r.xyxy[0])
        conf = float(r.conf)
        if conf > 0.3:
            detections.append([x1, y1, x2, y2, conf])

    if len(detections) == 0:
        detections = np.empty((0, 5))
    else:
        detections = np.array(detections)

    tracks = tracker.update(detections)

    for track in tracks:
        x1, y1, x2, y2, track_id = map(int, track)
        height = y2 - y1
        distance = estimate_distance(height)
        cv2.rectangle(frame_with_lanes, (x1, y1), (x2, y2), (0, 255, 255), 2)
        cv2.putText(frame_with_lanes, f"ID:{track_id}", (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)
        cv2.putText(frame_with_lanes, f"{distance}m", (x1, y2 + 20),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

    cv2.imshow("Real-Time Detection", frame_with_lanes)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
'''
